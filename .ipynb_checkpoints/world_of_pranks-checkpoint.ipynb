{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.2 (SDL 2.0.16, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Кирилл молодец\n",
<<<<<<< Updated upstream
    "# да мать вашу\n",
    "\n",
=======
    "#Белый давай партейку хватит уже\n",
>>>>>>> Stashed changes
    "import itertools\n",
    "import random\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from cmath import rect, pi, phase\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "from cars.agent import SimpleCarAgent\n",
    "from cars.track import plot_map\n",
    "from cars.utils import CarState, to_px, rotate, intersect_ray_with_segment, draw_text, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "black = (0, 0, 0)\n",
    "white = (255, 255, 255)\n",
    "\n",
    "\n",
    "class World(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def transition(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117.25731417, -96.27190342, -74.42893091,  44.58499534,\n",
       "        -0.46051512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(10,100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "# create data of complex numbers\n",
    "data = [1+2j, -1+4j, 4+3j, -4, 2-1j, 3+9j, -2+6j, 5]\n",
    "  \n",
    "# extract real part\n",
    "x = [ele.real for ele in data]\n",
    "# extract imaginary part\n",
    "y = [ele.imag for ele in data]\n",
    "  \n",
    "# plot the complex numbers\n",
    "plt.scatter(x, y)\n",
    "plt.ylabel('Imaginary')\n",
    "plt.xlabel('Real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "print(a.shape)\n",
    "b = a.reshape(3,1)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-2a3a9f6cbc12>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-2a3a9f6cbc12>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    COLLISION_PENALTY =  # выберите сами\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class SimpleCarWorld(World):\n",
    "    COLLISION_PENALTY =  # выберите сами\n",
    "    HEADING_REWARD =  # выберите сами\n",
    "    WRONG_HEADING_PENALTY =  # выберите сами\n",
    "    IDLENESS_PENALTY =  # выберите сами\n",
    "    SPEEDING_PENALTY =  # выберите сами\n",
    "    MIN_SPEED =  # выберите сами\n",
    "    MAX_SPEED =  # выберите сами\n",
    "\n",
    "    size = (800, 600)\n",
    "\n",
    "    def __init__(self, num_agents, car_map, Physics, agent_class, **physics_pars):\n",
    "        \"\"\"\n",
    "        Инициализирует мир\n",
    "        :param num_agents: число агентов в мире\n",
    "        :param car_map: карта, на которой всё происходит (см. track.py0\n",
    "        :param Physics: класс физики, реализующий столкновения и перемещения\n",
    "        :param agent_class: класс агентов в мире\n",
    "        :param physics_pars: дополнительные параметры, передаваемые в конструктор класса физики\n",
    "        (кроме car_map, являющейся обязательным параметром конструктора)\n",
    "        \"\"\"\n",
    "        self.physics = Physics(car_map, **physics_pars)\n",
    "        self.map = car_map\n",
    "\n",
    "        # создаём агентов\n",
    "        self.set_agents(num_agents, agent_class)\n",
    "\n",
    "        self._info_surface = pygame.Surface(self.size)\n",
    "\n",
    "    def set_agents(self, agents=1, agent_class=None): # функция которая добавляет машинки оппонентов на карту\n",
    "        \"\"\"\n",
    "        Поместить в мир агентов\n",
    "        :param agents: int или список Agent, если int -- то обязателен параметр agent_class, так как в мир присвоятся\n",
    "         agents агентов класса agent_class; если список, то в мир попадут все агенты из списка\n",
    "        :param agent_class: класс создаваемых агентов, если agents - это int\n",
    "        \"\"\"\n",
    "        pos = (self.map[0][0] + self.map[0][1]) / 2\n",
    "        vel = 0\n",
    "        heading = rect(-0.3, 1)\n",
    "\n",
    "        if type(agents) is int:\n",
    "            self.agents = [agent_class() for _ in range(agents)]\n",
    "        elif type(agents) is list:\n",
    "            self.agents = agents\n",
    "        else:\n",
    "            raise ValueError(\"Parameter agent should be int or list of agents instead of %s\" % type(agents))\n",
    "\n",
    "        self.agent_states = {a: CarState(pos, vel, heading) for a in self.agents}\n",
    "        self.circles = {a: 0 for a in self.agents}\n",
    "\n",
    "        self._agent_surfaces = []\n",
    "        self._agent_images = []\n",
    "\n",
    "    def transition(self):\n",
    "        \"\"\"\n",
    "        Логика основного цикла:\n",
    "         подсчёт для каждого агента видения агентом мира,\n",
    "         выбор действия агентом,\n",
    "         смена состояния\n",
    "         и обработка реакции мира на выбранное действие\n",
    "        \"\"\"\n",
    "        for a in self.agents:\n",
    "            vision = self.vision_for(a)\n",
    "            action = a.choose_action(vision)\n",
    "            next_agent_state, collision = self.physics.move(\n",
    "                self.agent_states[a], action\n",
    "            )\n",
    "            self.circles[a] += angle(self.agent_states[a].position, next_agent_state.position) / (2*pi)\n",
    "            self.agent_states[a] = next_agent_state\n",
    "            a.receive_feedback(self.reward(next_agent_state, collision))\n",
    "\n",
    "    def reward(self, state, collision):\n",
    "        \"\"\"\n",
    "        Вычисление награды агента, находящегося в состоянии state.\n",
    "        Эту функцию можно (и иногда нужно!) менять, чтобы обучить вашу сеть именно тем вещам, которые вы от неё хотите\n",
    "        :param state: текущее состояние агента\n",
    "        :param collision: произошло ли столкновение со стеной на прошлом шаге\n",
    "        :return reward: награду агента (возможно, отрицательную)\n",
    "        \"\"\"\n",
    "        a = np.sin(angle(-state.position, state.heading))\n",
    "        heading_reward = 1 if a > 0.1 else a if a > 0 else 0\n",
    "        heading_penalty = a if a <= 0 else 0\n",
    "        idle_penalty = 0 if abs(state.velocity) > self.MIN_SPEED else -self.IDLENESS_PENALTY\n",
    "        speeding_penalty = 0 if abs(state.velocity) < self.MAX_SPEED else -self.SPEEDING_PENALTY * abs(state.velocity)\n",
    "        collision_penalty = - max(abs(state.velocity), 0.1) * int(collision) * self.COLLISION_PENALTY\n",
    "\n",
    "        return heading_reward * self.HEADING_REWARD + heading_penalty * self.WRONG_HEADING_PENALTY + collision_penalty \\\n",
    "               + idle_penalty + speeding_penalty\n",
    "\n",
    "    def eval_reward(self, state, collision):\n",
    "        \"\"\"\n",
    "        Награда \"по умолчанию\", используется в режиме evaluate\n",
    "        Удобно, чтобы не приходилось отменять свои изменения в функции reward для оценки результата\n",
    "        \"\"\"\n",
    "        a = -np.sin(angle(-state.position, state.heading))\n",
    "        heading_reward = 1 if a > 0.1 else a if a > 0 else 0\n",
    "        heading_penalty = a if a <= 0 else 0\n",
    "        idle_penalty = 0 if abs(state.velocity) > self.MIN_SPEED else -self.IDLENESS_PENALTY\n",
    "        speeding_penalty = 0 if abs(state.velocity) < self.MAX_SPEED else -self.SPEEDING_PENALTY * abs(state.velocity)\n",
    "        collision_penalty = - max(abs(state.velocity), 0.1) * int(collision) * self.COLLISION_PENALTY\n",
    "\n",
    "        return heading_reward * self.HEADING_REWARD + heading_penalty * self.WRONG_HEADING_PENALTY + collision_penalty \\\n",
    "            + idle_penalty + speeding_penalty\n",
    "\n",
    "    def run(self, steps=None):\n",
    "        \"\"\"\n",
    "        Основной цикл мира; по завершении сохраняет текущие веса агента в файл network_config_agent_n_layers_....txt\n",
    "        :param steps: количество шагов цикла; до внешней остановки, если None\n",
    "        \"\"\"\n",
    "        scale = self._prepare_visualization()\n",
    "        for _ in range(steps) if steps is not None else itertools.count():\n",
    "            self.transition()\n",
    "            self.visualize(scale)\n",
    "            if self._update_display() == pygame.QUIT:\n",
    "                break\n",
    "            sleep(0.1)\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            try:\n",
    "                filename = \"network_config_agent_%d_layers_%s.txt\" % (i, \"_\".join(map(str, agent.neural_net.sizes)))\n",
    "                agent.to_file(filename)\n",
    "                print(\"Saved agent parameters to '%s'\" % filename)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "    def evaluate_agent(self, agent, steps=1000, visual=True):\n",
    "        \"\"\"\n",
    "        Прогонка цикла мира для конкретного агента (см. пример использования в комментариях после if _name__ == \"__main__\")\n",
    "        :param agent: SimpleCarAgent\n",
    "        :param steps: количество итераций цикла\n",
    "        :param visual: рисовать картинку или нет\n",
    "        :return: среднее значение награды агента за шаг\n",
    "        \"\"\"\n",
    "        agent.evaluate_mode = True\n",
    "        self.set_agents([agent])\n",
    "        rewards = []\n",
    "        if visual:\n",
    "            scale = self._prepare_visualization()\n",
    "        for _ in range(steps):\n",
    "            vision = self.vision_for(agent)\n",
    "            action = agent.choose_action(vision)\n",
    "            next_agent_state, collision = self.physics.move(\n",
    "                self.agent_states[agent], action\n",
    "            )\n",
    "            self.circles[agent] += angle(self.agent_states[agent].position, next_agent_state.position) / (2*pi)\n",
    "            self.agent_states[agent] = next_agent_state\n",
    "            rewards.append(self.eval_reward(next_agent_state, collision))\n",
    "            agent.receive_feedback(rewards[-1])\n",
    "            if visual:\n",
    "                self.visualize(scale)\n",
    "                if self._update_display() == pygame.QUIT:\n",
    "                    break\n",
    "                sleep(0.05)\n",
    "\n",
    "        return np.mean(rewards)\n",
    "\n",
    "    def vision_for(self, agent):\n",
    "        \"\"\"\n",
    "        Строит видение мира для каждого агента\n",
    "        :param agent: машинка, из которой мы смотрим\n",
    "        :return: список из модуля скорости машинки, направленного угла между направлением машинки\n",
    "        и направлением на центр и `agent.rays` до ближайших стен трека (запустите картинку, и станет совсем понятно)\n",
    "        \"\"\"\n",
    "        state = self.agent_states[agent]\n",
    "        vision = [abs(state.velocity), np.sin(angle(-state.position, state.heading))]\n",
    "        extras = len(vision)\n",
    "\n",
    "        delta = pi / (agent.rays - 1)\n",
    "        start = rotate(state.heading, - pi / 2)\n",
    "\n",
    "        sectors = len(self.map)\n",
    "        for i in range(agent.rays):\n",
    "            # define ray direction\n",
    "            ray = rotate(start, i * delta)\n",
    "\n",
    "            # define ray's intersections with walls\n",
    "            vision.append(np.infty)\n",
    "            for j in range(sectors):\n",
    "                inner_wall = self.map[j - 1][0], self.map[j][0]\n",
    "                outer_wall = self.map[j - 1][1], self.map[j][1]\n",
    "\n",
    "                intersect = intersect_ray_with_segment((state.position, ray), inner_wall)\n",
    "                intersect = abs(intersect - state.position) if intersect is not None else np.infty\n",
    "                if intersect < vision[-1]:\n",
    "                    vision[-1] = intersect\n",
    "\n",
    "                intersect = intersect_ray_with_segment((state.position, ray), outer_wall)\n",
    "                intersect = abs(intersect - state.position) if intersect is not None else np.infty\n",
    "                if intersect < vision[-1]:\n",
    "                    vision[-1] = intersect\n",
    "\n",
    "            assert vision[-1] < np.infty, \\\n",
    "                \"Something went wrong: {}, {}\".format(str(state), str(agent.chosen_actions_history[-1]))\n",
    "        assert len(vision) == agent.rays + extras, \\\n",
    "            \"Something went wrong: {}, {}\".format(str(state), str(agent.chosen_actions_history[-1]))\n",
    "        return vision #возвращаем скорость, синус угла от радиального направления и координаты пересечения с ближайшей стенкой\n",
    "\n",
    "    def visualize(self, scale):\n",
    "        \"\"\"\n",
    "        Рисует картинку. Этот и все \"приватные\" (начинающиеся с _) методы необязательны для разбора.\n",
    "        \"\"\"\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            state = self.agent_states[agent]\n",
    "            surface = self._agent_surfaces[i]\n",
    "            rays_lengths = self.vision_for(agent)[-agent.rays:]\n",
    "            self._agent_images[i] = [self._draw_ladar(rays_lengths, state, scale),\n",
    "                                     self._get_agent_image(surface, state, scale)]\n",
    "\n",
    "        if len(self.agents) == 1:\n",
    "            a = self.agents[0]\n",
    "            draw_text(\"Reward: %.3f\" % a.reward_history[-1], self._info_surface, scale, self.size,\n",
    "                      text_color=white, bg_color=black)\n",
    "            steer, acc = a.chosen_actions_history[-1]\n",
    "            state = self.agent_states[a]\n",
    "            draw_text(\"Action: steer.: %.2f, accel: %.2f\" % (steer, acc), self._info_surface, scale,\n",
    "                      self.size, text_color=white, bg_color=black, tlpoint=(self._info_surface.get_width() - 500, 10))\n",
    "            draw_text(\"Inputs: |v|=%.2f, sin(angle): %.2f, circle: %.2f\" % (\n",
    "                abs(state.velocity), np.sin(angle(-state.position, state.heading)), self.circles[a]),\n",
    "                      self._info_surface, scale,\n",
    "                      self.size, text_color=white, bg_color=black, tlpoint=(self._info_surface.get_width() - 500, 50))\n",
    "\n",
    "    def _get_agent_image(self, original, state, scale):\n",
    "        angle = phase(state.heading) * 180 / pi\n",
    "        rotated = pygame.transform.rotate(original, angle)\n",
    "        rectangle = rotated.get_rect()\n",
    "        rectangle.center = to_px(state.position, scale, self.size)\n",
    "        return rotated, rectangle\n",
    "\n",
    "    def _draw_ladar(self, sensors, state, scale):\n",
    "        surface = pygame.display.get_surface().copy()\n",
    "        surface.fill(white)\n",
    "        surface.set_colorkey(white)\n",
    "        start_pos = to_px(state.position, scale, surface.get_size())\n",
    "        delta = pi / (len(sensors) - 1)\n",
    "        ray = phase(state.heading) - pi / 2\n",
    "        for s in sensors:\n",
    "            end_pos = to_px(rect(s, ray) + state.position, scale, surface.get_size())\n",
    "            pygame.draw.line(surface, (0, 255, 0), start_pos, end_pos, 2)\n",
    "            ray += delta\n",
    "\n",
    "        rectangle = surface.get_rect()\n",
    "        rectangle.topleft = (0, 0)\n",
    "        return surface, rectangle\n",
    "\n",
    "    def _prepare_visualization(self):\n",
    "        red = (254, 0, 0)\n",
    "        pygame.init()\n",
    "        screen = pygame.display.set_mode(self.size)\n",
    "        screen.fill(white)\n",
    "        scale = plot_map(self.map, screen)\n",
    "        for state in self.agent_states.values():\n",
    "            s = pygame.Surface((25, 15))\n",
    "            s.set_colorkey(white)\n",
    "            s.fill(white)\n",
    "            pygame.draw.rect(s, red, pygame.Rect(0, 0, 15, 15))\n",
    "            pygame.draw.polygon(s, red, [(15, 0), (25, 8), (15, 15)], 0)\n",
    "            self._agent_surfaces.append(s)\n",
    "            self._agent_images.append([self._get_agent_image(s, state, scale)])\n",
    "\n",
    "        self._map_surface = screen\n",
    "        return scale\n",
    "\n",
    "    def _update_display(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                return pygame.QUIT\n",
    "        display = pygame.display.get_surface()\n",
    "        display.fill(white)\n",
    "\n",
    "        plot_map(self.map, display)\n",
    "        for images in self._agent_images:\n",
    "            for surf, rectangle in images:\n",
    "                display.blit(surf, rectangle)\n",
    "        display.blit(self._info_surface, (0, 0), None, pygame.BLEND_RGB_SUB)\n",
    "        self._info_surface.fill(black)  # clear notifications from previous round\n",
    "        pygame.display.update()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from HW_3.cars.physics import SimplePhysics\n",
    "    from HW_3.cars.track import generate_map\n",
    "\n",
    "    np.random.seed(3)\n",
    "    random.seed(3)\n",
    "    m = generate_map(8, 5, 3, 3)\n",
    "    SimpleCarWorld(1, m, SimplePhysics, SimpleCarAgent, timedelta=0.2).run()\n",
    "\n",
    "    # если вы хотите продолжить обучение уже существующей модели, вместо того,\n",
    "    # чтобы создавать новый мир с новыми агентами, используйте код ниже:\n",
    "    # # он загружает агента из файла\n",
    "    # agent = SimpleCarAgent.from_file('filename.txt')\n",
    "    # # создаёт мир\n",
    "    # w = SimpleCarWorld(1, m, SimplePhysics, SimpleCarAgent, timedelta=0.2)\n",
    "    # # подключает к нему агента\n",
    "    # w.set_agents([agent])\n",
    "    # # и запускается\n",
    "    # w.run()\n",
    "    # # или оценивает агента в этом мире\n",
    "    # print(w.evaluate_agent(agent, 500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.7382075526911813-3.2521459863997246j), (-1.4022868358290597-6.177722631389064j)]\n",
      "[(4.034538817159051-6.6768335213094065j), (5.586059998603128-9.244474855984166j)]\n",
      "[(2.2539188834738164-1.7804148389566867j), (4.6080564795720855-3.6399944093533567j)]\n",
      "[(5.050188928530075+1.2268431461805964j), (7.965401225583332+1.9350361023087097j)]\n",
      "[(1.7655123882754664+0.46847900267766496j), (4.665165406033008+1.2379024079686531j)]\n",
      "[(4.4034790533998684+3.236136432080141j), (6.820881564029797+5.0126963386411685j)]\n",
      "[(0.2873629078605085+3.3127339616104243j), (0.5466241257033826+6.301510236429707j)]\n",
      "[(-9.515882152833548+1.1653594619531028e-15j), (-12.515882152833548+1.5327535016973089e-15j)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-0.7382075526911813-3.2521459863997246j),\n",
       " (4.034538817159051-6.6768335213094065j),\n",
       " (2.2539188834738164-1.7804148389566867j),\n",
       " (5.050188928530075+1.2268431461805964j),\n",
       " (1.7655123882754664+0.46847900267766496j),\n",
       " (4.4034790533998684+3.236136432080141j),\n",
       " (0.2873629078605085+3.3127339616104243j),\n",
       " (-9.515882152833548+1.1653594619531028e-15j)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_map(sectors, radius, width, scale):\n",
    "    \"\"\"\n",
    "    :param sectors: number of sectors in the map\n",
    "    :param radius: average distance between 0 and inner point of map\n",
    "    :param width: distance between inner and outer points of map\n",
    "    :param scale: scale of radius variation, as in np.random.normal(loc=radius, scale=scale, size=sectors)\n",
    "    :return: list of tuples (`inner_point`, `outer_point`) of length :param sectors:\n",
    "    \"\"\"\n",
    "    sector_angles = get_partition(sectors, -pi, pi)\n",
    "    sector_radii = np.random.normal(loc=radius, scale=scale, size=sectors)\n",
    "    sector_radii[sector_radii <= 0] = 1e-6\n",
    "    inner_points = [rect(r, phi) for phi, r in zip(sector_angles, sector_radii)]\n",
    "    outer_points = [rect(r, phi) for phi, r in zip(sector_angles, sector_radii + width)]\n",
    "    return list(zip(inner_points, outer_points))\n",
    "def get_partition(n, a, b=None):\n",
    "    if b is None:\n",
    "        b = a\n",
    "        a = 0\n",
    "    sample = np.random.rand(n)\n",
    "    return a + (b - a) * np.cumsum(sample / sample.sum())\n",
    "m_new= []\n",
    "m = generate_map(8, 5, 3, 3)\n",
    "for each in m: \n",
    "    m_new.append(each[0])\n",
    "#     m_new.append(each[1])\n",
    "    print(list(each))\n",
    "    \n",
    "m_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "# create data of complex numbers\n",
    "data = m_new[0:8]\n",
    "  \n",
    "# extract real part\n",
    "x = [ele.real for ele in data]\n",
    "# extract imaginary part\n",
    "y = [ele.imag for ele in data]\n",
    "  \n",
    "# plot the complex numbers\n",
    "plt.scatter(x, y)\n",
    "plt.grid(color='0.25')\n",
    "plt.ylabel('Imaginary')\n",
    "plt.xlabel('Real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.252441295442369+0.16209069176044186j)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading = rect(-0.3, 1)\n",
    "rotate(heading, -pi/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
